{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Perform combined over and undersampling on the diabetes dataset (use SMOTEENN). Explain how combined sampling works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combination of random oversampling and undersampling for imbalanced classification\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df = pd.read_csv('../week_13/diabetes.csv')\n",
    "diabetes_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looking for null values in the df\n",
    "diabetes_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df['Outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definining X and Y variables\n",
    "X=diabetes_df.drop('Outcome',axis=1) #Features\n",
    "Y=diabetes_df['Outcome'].values #Target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Synthetic minority Oversampling technique - SMOTE\n",
    "#sampling_strategy used here for EditedNearestNeighbours is 'all'. because ENN purpose is to delete some observations from both classes that are identified as having different class between the observationâ€™s class and its K-nearest neighbor majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.7314\n",
      "Mean Precision: 0.7278\n",
      "Mean Recall: 0.7461\n"
     ]
    }
   ],
   "source": [
    "##Using SMOTE-ENN to balance the data\n",
    "#Define model\n",
    "model=AdaBoostClassifier()\n",
    "#Define SMOTE-ENN\n",
    "resample=SMOTEENN(enn=EditedNearestNeighbours(sampling_strategy='all'))\n",
    "#Define pipeline\n",
    "pipeline=Pipeline(steps=[('r', resample), ('m', model)])\n",
    "#Define evaluation procedure (here we use Repeated Stratified K-Fold CV)\n",
    "cv=RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "#Evaluate model\n",
    "scoring=['accuracy','precision_macro','recall_macro']\n",
    "scores = cross_validate(pipeline, X, Y, scoring=scoring, cv=cv, n_jobs=-1)\n",
    "\n",
    "# summarize performance\n",
    "print('Mean Accuracy: %.4f' % np.mean(scores['test_accuracy']))\n",
    "print('Mean Precision: %.4f' % np.mean(scores['test_precision_macro']))\n",
    "print('Mean Recall: %.4f' % np.mean(scores['test_recall_macro']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Comment on the performance of combined sampling vs the other approaches we have used for the diabetes dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling results form (week_15/Inclass_practice.ipynb)\n",
    "Precision - 0.76\n",
    "Recall - 0.74\n",
    "Accuracy - 0.74\n",
    "Undersampling results:\n",
    "Precision - 0.76\n",
    "Recall - 0.74\n",
    "precision = True Positives/True Positives + false positives\n",
    "Precision and accuracy dropped a bit after handling imbalanced dataset with SMOTEEN to balance. \n",
    "Though recall remained the same. \n",
    "Values when performed individually or either combined didn't make any difference here in this dataset. But SMOTE-ENN being the advanced model values looks more accurate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. What is outlier detection? Why is it useful? What methods can you use for outlier detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outlier is a deviation from the pattern or an extreme value from other observations in a dataset i.e., abnormal data points in data. Abnormal data is detected when preparing datasets for ML models. \n",
    "Generally we either remove them or analyse them to see why we got those readings. Finding abnormalities helps in predicting future methods. \n",
    "Methods to defect outliers are:\n",
    "    1. Z-score / Etreme value analysis / standard deviation: 68% of data points lie within one standard deviation of the mean, 95% within 2 standard deviation, 99.7% lie within 3. Data points that are more than 3 times the standard deviation are considered outliers. \n",
    "    2. Boxplots: Data points that are above and below the whiskers are considered outliers\n",
    "    3. DBScan clustering(Density based spatial clustering of applications with noise): Kmeans and heirachial clustering can also be used to detect outliers. \n",
    "        a. Core points: i. min_samples(minimum no. of core points needed to form a cluster). ii. eps(max distance between two samples for them to consider as in the same cluster)\n",
    "        b. Border points: these are points in the same cluster as core points but much further away from the center of the cluster\n",
    "        c. Noise point: Data points that do not belong to any cluster. These are considered as abnormal or normal\n",
    "    4. Isolation Forest: Outliers are few and far from the rest of the observations\n",
    "    5. Robust Random Cut Forest\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Perform a linear SVM to predict credit approval (last column) using this dataset: https://archive.ics.uci.edu/ml/datasets/Statlog+%28Australian+Credit+Approval%29 . Make sure you look at the accompanying document that describes the data in the dat file. You will need to either convert this data to another file type or import the dat file to python. \n",
    "You can use this code, but otherwise you follow standard practices we have already used many times: \n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2267</th>\n",
       "      <th>7</th>\n",
       "      <th>2</th>\n",
       "      <th>8</th>\n",
       "      <th>4</th>\n",
       "      <th>0165</th>\n",
       "      <th>0_1</th>\n",
       "      <th>0_2</th>\n",
       "      <th>0_3</th>\n",
       "      <th>0_4</th>\n",
       "      <th>2_1</th>\n",
       "      <th>160</th>\n",
       "      <th>1</th>\n",
       "      <th>0_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>29.58</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>280</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>21.67</td>\n",
       "      <td>11.50</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>20.17</td>\n",
       "      <td>8.17</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   2267      7  2  8  4  0165  0_1  0_2  0_3  0_4  2_1  160    1  0_5\n",
       "0  0  29.58   1.75  1  4  4  1.25    0    0    0    1    2  280    1    0\n",
       "1  0  21.67  11.50  1  5  3  0.00    1    1   11    1    2    0    1    1\n",
       "2  1  20.17   8.17  2  6  4  1.96    1    1   14    0    2   60  159    1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_file = np.genfromtxt('/Users/trimpu/Downloads/australian.dat',\n",
    "                     skip_header=1,\n",
    "                     skip_footer=1,\n",
    "                     names=True,\n",
    "                     dtype=None,\n",
    "                     delimiter=' ')\n",
    "#data_file.shape\n",
    "df = pd.DataFrame(data_file)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>29.58</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>280</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>21.67</td>\n",
       "      <td>11.50</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A1     A2     A3  A4  A5  A6    A7  A8  A9  A10  A11  A12  A13  A14  A15\n",
       "0   0  29.58   1.75   1   4   4  1.25   0   0    0    1    2  280    1    0\n",
       "1   0  21.67  11.50   1   5   3  0.00   1   1   11    1    2    0    1    1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#renaming the columns\n",
    "df.columns = ['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'A11', 'A12', 'A13', 'A14','A15']\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1     0\n",
       "A2     0\n",
       "A3     0\n",
       "A4     0\n",
       "A5     0\n",
       "A6     0\n",
       "A7     0\n",
       "A8     0\n",
       "A9     0\n",
       "A10    0\n",
       "A11    0\n",
       "A12    0\n",
       "A13    0\n",
       "A14    0\n",
       "A15    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for null_values. Preprocessing\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining X and y values\n",
    "X = df.drop('A15', axis=1)\n",
    "y = df['A15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset into training and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8797814207650273\n",
      "0.8260869565217391\n"
     ]
    }
   ],
   "source": [
    "#fit and train the training data\n",
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(X_train, y_train)\n",
    "print(svclassifier.score(X_train, y_train))\n",
    "print(svclassifier.score(X_test, y_test ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = svclassifier.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[57 13]\n",
      " [11 57]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.83        70\n",
      "           1       0.81      0.84      0.83        68\n",
      "\n",
      "    accuracy                           0.83       138\n",
      "   macro avg       0.83      0.83      0.83       138\n",
      "weighted avg       0.83      0.83      0.83       138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "5. How did the SVM model perform? Use a classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.83        70\n",
      "           1       0.81      0.84      0.83        68\n",
      "\n",
      "    accuracy                           0.83       138\n",
      "   macro avg       0.83      0.83      0.83       138\n",
      "weighted avg       0.83      0.83      0.83       138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[57 13]\n",
    " [11 57]]\n",
    "\n",
    "[[TP  FP]\n",
    "[FN   TN]]\n",
    "\n",
    "\n",
    "* updating comments - Based on precision and recall dataset looks very balanced. I believe realtime datasets doesn't show up such accurate correlation between precision and recall. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. What kinds of jobs in data are you most interested in? Do some research on what is out there. Write about your thoughts in under 400 words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Interested in playing with data, exploring datasets, visualizing data and making predictions that deliver business value. \n",
    "* Any data related technical job where i can use my skills that i learned at launch code and learn new skills. It needs to be more challenging because i get bored in doing same routine task without learning any new stuff. \n",
    "* Eventually looking for desiging and developing machine learning and deep learning systems, and learning data analysis tools.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
